{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Aircraft Based On Photos - Part 1\n",
    "An attempt to identify aircraft models based on photos without relying on any additional information (i.e., no EXIF data, no tags, etc.).\n",
    "\n",
    "- **For part 1**, I train an image classifier (a convolutional neural network, aka *CNN*) to distinguish between photos of Airbus **<a href=\"http://www.airbus.com/aircraftfamilies/passengeraircraft/a320family/a321/\" target=\"_blank\">A321</a>**s and **<a href=\"http://www.airbus.com/aircraftfamilies/passengeraircraft/a340family/\" target=\"_blank\">A340</a>**s.\n",
    " - The CNN comprises of 3 sets of (convolution + activation + max-pooling layers), followed by 2 fully-connected layers\n",
    " ![](https://docs.google.com/drawings/d/1B7g5OCWWrKzFPE_hOj0yvVsN6PBxiov54MjmGW8FNYE/pub?w=959&h=429)\n",
    "- In subsequent parts, I'll be extending this work to recognize and distinguish between photos of 15+ different models of commercial aircraft.\n",
    "\n",
    "## Dataset\n",
    "All required photos of aircrafts are under the `train` and `test` subdirectories of the `data` directory. All photos used should have already been resized into the standard size, i.e. 1024 x 683 pixels and placed in aircraft model specific subdirectories of the `train` and `test` subdirectories.\n",
    "\n",
    "- Train data : 1106 and 1052 photos for A321 and A340 models respectively.\n",
    "- Test data  : 225 and 125 photos respectively.\n",
    "\n",
    "To make up for having a tiny dataset to work with, photos are augmented using several random transformations. As an example, the image on the top is the original, 3 of (*potentially infinite*) transformations are shown below.\n",
    "![](https://docs.google.com/drawings/d/1vQ6hsOmnHD15vC3m_g77HG7oirvK1PpHzMQP163fUTI/pub?w=827&h=321)\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(730521) # For reproducibility, needs to be set before Keras is loaded\n",
    "from imp import reload\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "reload(logging)\n",
    "logging.basicConfig(format=\"%(asctime)s: %(message)s\", level=logging.INFO, datefmt=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:36:32: Current PID : 4464\n"
     ]
    }
   ],
   "source": [
    "#img_width, img_height = 256, 170 # Approximately 25% of the original\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = \"../data/train\"\n",
    "validation_data_dir = \"../data/test\"\n",
    "\n",
    "nb_train_samples = 2000 # actual 2158\n",
    "nb_validation_samples = 350\n",
    "nb_epoch = 20\n",
    "\n",
    "logging.info(\"Current PID : {}\".format(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_input_shape = (3, img_width, img_height)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test generators load the photos and indefinitely generate batches of augmented photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2158 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "labels = [\"A321\", \"A340\"]\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    batch_size=32,\n",
    "    classes=labels,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    batch_size=32,\n",
    "    classes=labels,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda/lib/python3.5/site-packages/keras/engine/training.py:1432: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152s - loss: 0.7563 - acc: 0.5531 - val_loss: 0.6758 - val_acc: 0.5600\n",
      "Epoch 2/20\n",
      "153s - loss: 0.6401 - acc: 0.6389 - val_loss: 0.6575 - val_acc: 0.5971\n",
      "Epoch 3/20\n",
      "157s - loss: 0.5772 - acc: 0.6926 - val_loss: 0.6560 - val_acc: 0.6057\n",
      "Epoch 4/20\n",
      "156s - loss: 0.5264 - acc: 0.7212 - val_loss: 0.8842 - val_acc: 0.4857\n",
      "Epoch 5/20\n",
      "151s - loss: 0.4926 - acc: 0.7626 - val_loss: 0.5853 - val_acc: 0.6771\n",
      "Epoch 6/20\n",
      "151s - loss: 0.4418 - acc: 0.7931 - val_loss: 0.6307 - val_acc: 0.6686\n",
      "Epoch 7/20\n",
      "152s - loss: 0.4085 - acc: 0.8158 - val_loss: 0.4522 - val_acc: 0.8086\n",
      "Epoch 8/20\n",
      "151s - loss: 0.3740 - acc: 0.8414 - val_loss: 0.4426 - val_acc: 0.7800\n",
      "Epoch 9/20\n",
      "152s - loss: 0.3216 - acc: 0.8650 - val_loss: 0.3453 - val_acc: 0.8771\n",
      "Epoch 10/20\n",
      "153s - loss: 0.2838 - acc: 0.8862 - val_loss: 0.6225 - val_acc: 0.6943\n",
      "Epoch 11/20\n",
      "153s - loss: 0.2666 - acc: 0.8877 - val_loss: 0.3435 - val_acc: 0.8486\n",
      "Epoch 12/20\n",
      "152s - loss: 0.2155 - acc: 0.9089 - val_loss: 0.5461 - val_acc: 0.8057\n",
      "Epoch 13/20\n",
      "153s - loss: 0.2095 - acc: 0.9138 - val_loss: 0.5070 - val_acc: 0.7829\n",
      "Epoch 14/20\n",
      "155s - loss: 0.2157 - acc: 0.9158 - val_loss: 0.2245 - val_acc: 0.9057\n",
      "Epoch 15/20\n",
      "155s - loss: 0.1682 - acc: 0.9330 - val_loss: 0.2193 - val_acc: 0.9000\n",
      "Epoch 16/20\n",
      "154s - loss: 0.1823 - acc: 0.9246 - val_loss: 0.3526 - val_acc: 0.8714\n",
      "Epoch 17/20\n",
      "147s - loss: 0.1635 - acc: 0.9370 - val_loss: 0.2697 - val_acc: 0.8714\n",
      "Epoch 18/20\n",
      "154s - loss: 0.1449 - acc: 0.9473 - val_loss: 0.5214 - val_acc: 0.8286\n",
      "Epoch 19/20\n",
      "152s - loss: 0.1427 - acc: 0.9443 - val_loss: 0.3492 - val_acc: 0.8714\n",
      "Epoch 20/20\n",
      "153s - loss: 0.1426 - acc: 0.9448 - val_loss: 0.3633 - val_acc: 0.8829\n",
      "[WARNING] model_1_weights_20_epochs.h5 already exists - overwrite? [y/n]y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:28:10: Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIP] Next time specify overwrite=True in save_weights!\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    nb_val_samples=nb_validation_samples,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=2)\n",
    "model.save_weights(\"model_1_weights_{}_epochs.h5\".format(nb_epoch))\n",
    "logging.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Credits\n",
    "- <a href=\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\" target=\"_blank\">https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
