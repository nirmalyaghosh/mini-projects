{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Aircraft Based On Limited Number Of Photos - Part 1\n",
    "This is an attempt to train a deep neural network to identify different models of commercial aircraft based on very few photos - without relying on any additional information (i.e., no EXIF data, no tags, etc.). The underlying technique can be used for other image classification tasks where we have a small training dataset.\n",
    "\n",
    "I train a convolutional neural network (aka *CNN*) to distinguish between photos of different models of commercial aircraft. The CNN comprises of 3 sets of (convolution + activation + max-pooling layers), followed by 2 fully-connected layers, as shown below:\n",
    "![](https://docs.google.com/drawings/d/1B7g5OCWWrKzFPE_hOj0yvVsN6PBxiov54MjmGW8FNYE/pub?w=959&h=429)\n",
    "\n",
    "## Dataset\n",
    "As of date, I have curated a dataset of 5920 photos of 39 different models of commercial aircraft ([TSV](https://docs.google.com/spreadsheets/d/1zSUNhlpGDKtngK271UMJobtXcwojHiewczJ5FLpX4Es/pub?output=tsv), [Web](https://docs.google.com/spreadsheets/d/1zSUNhlpGDKtngK271UMJobtXcwojHiewczJ5FLpX4Es/pubhtml)). They were obtained from the Yahoo Flickr Creative Commons (YFCC) dataset, Wikipedia and other sources.\n",
    "\n",
    "The photos have been harvested from the indicated `ImageURL`s and placed in aircraft model specific subdirectories of the `train` and `test` subdirectories of the `data` directory. The script should have already resized the photos into the standard size, i.e. 1024 x 683 pixels.\n",
    "\n",
    "#### Tiny Dataset\n",
    "To make up for having a tiny dataset to work with, photos are augmented using several random transformations. As an example, the image on the top is the original, 3 of (*potentially infinite*) transformations are shown below.\n",
    "![](https://docs.google.com/drawings/d/1vQ6hsOmnHD15vC3m_g77HG7oirvK1PpHzMQP163fUTI/pub?w=827&h=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "I trained the classifier on 4 aircraft models for which I have the most number of photos, as shown below. I have added a few columns which serves as features for visual identification (but not used for training).\n",
    "\n",
    "| Aircraft Model | Train | Test | NumberOfEngines | EngineMount | Wingtips | OverWingExits | T-tail |\n",
    "|----------------|-------|------|-----------------|-------------|----------|---------------|--------|\n",
    "| A321           | 1106  | 225  | 2               | Under Wing  | Small    | None          | No     |\n",
    "| A340           | 1052  | 125  | 4               | Under Wing  | Medium   | None          | No     |\n",
    "| B747           | 1169  | 150  | 4               | Under Wing  | Large    | 1             | No     |\n",
    "| CRJ900         | 304   | 130  | 2               | Rear        | Medium   | 2             | Yes    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(371250) # For reproducibility, needs to be set before Keras is loaded\n",
    "from imp import reload\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "reload(logging)\n",
    "logging.basicConfig(format=\"%(asctime)s: %(message)s\", level=logging.INFO, datefmt=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:06:31: Current PID : 2093\n"
     ]
    }
   ],
   "source": [
    "#img_width, img_height = 256, 170 # Approximately 25% of the original\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = \"../data/train\"\n",
    "validation_data_dir = \"../data/test\"\n",
    "\n",
    "labels = [\"A321\", \"A340\", \"B747\", \"CRJ900\"]\n",
    "nb_train_samples = 3700 # actual 3726\n",
    "nb_validation_samples = 630\n",
    "nb_epoch = 20\n",
    "\n",
    "logging.info(\"Current PID : {}\".format(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_input_shape = (3, img_width, img_height)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels)))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test generators load the photos and indefinitely generate batches of augmented photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    fill_mode=\"nearest\",\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3726 images belonging to 4 classes.\n",
      "Found 630 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    batch_size=32,\n",
    "    classes=labels,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    batch_size=32,\n",
    "    classes=labels,\n",
    "    target_size=(img_width, img_height),\n",
    "    class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/miniconda/lib/python3.5/site-packages/keras/engine/training.py:1432: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414s - loss: 1.2779 - acc: 0.3489 - val_loss: 1.4801 - val_acc: 0.2349\n",
      "Epoch 2/20\n",
      "372s - loss: 1.2190 - acc: 0.4055 - val_loss: 1.3702 - val_acc: 0.2921\n",
      "Epoch 3/20\n",
      "358s - loss: 1.1527 - acc: 0.4557 - val_loss: 1.3290 - val_acc: 0.3492\n",
      "Epoch 4/20\n",
      "373s - loss: 1.0743 - acc: 0.5220 - val_loss: 1.2505 - val_acc: 0.4079\n",
      "Epoch 5/20\n",
      "371s - loss: 0.9636 - acc: 0.6020 - val_loss: 1.0415 - val_acc: 0.5667\n",
      "Epoch 6/20\n",
      "390s - loss: 0.8492 - acc: 0.6592 - val_loss: 0.9655 - val_acc: 0.6127\n",
      "Epoch 7/20\n",
      "447s - loss: 0.7783 - acc: 0.6975 - val_loss: 0.8281 - val_acc: 0.6587\n",
      "Epoch 8/20\n",
      "415s - loss: 0.6852 - acc: 0.7338 - val_loss: 0.7147 - val_acc: 0.7365\n",
      "Epoch 9/20\n",
      "441s - loss: 0.6525 - acc: 0.7461 - val_loss: 0.6405 - val_acc: 0.7587\n",
      "Epoch 10/20\n",
      "442s - loss: 0.5973 - acc: 0.7689 - val_loss: 0.7014 - val_acc: 0.7413\n",
      "Epoch 11/20\n",
      "398s - loss: 0.5671 - acc: 0.7743 - val_loss: 0.5731 - val_acc: 0.7603\n",
      "Epoch 12/20\n",
      "372s - loss: 0.5270 - acc: 0.7971 - val_loss: 0.5835 - val_acc: 0.7810\n",
      "Epoch 13/20\n",
      "423s - loss: 0.5075 - acc: 0.8065 - val_loss: 0.5557 - val_acc: 0.7952\n",
      "Epoch 14/20\n",
      "438s - loss: 0.4816 - acc: 0.8103 - val_loss: 0.6794 - val_acc: 0.7365\n",
      "Epoch 15/20\n",
      "351s - loss: 0.4506 - acc: 0.8306 - val_loss: 0.4353 - val_acc: 0.8508\n",
      "Epoch 16/20\n",
      "367s - loss: 0.4607 - acc: 0.8237 - val_loss: 0.6326 - val_acc: 0.7476\n",
      "Epoch 17/20\n",
      "353s - loss: 0.4322 - acc: 0.8430 - val_loss: 0.5124 - val_acc: 0.7952\n",
      "Epoch 18/20\n",
      "350s - loss: 0.4125 - acc: 0.8360 - val_loss: 0.5515 - val_acc: 0.8048\n",
      "Epoch 19/20\n",
      "351s - loss: 0.4046 - acc: 0.8438 - val_loss: 0.4111 - val_acc: 0.8413\n",
      "Epoch 20/20\n",
      "352s - loss: 0.3793 - acc: 0.8497 - val_loss: 0.4129 - val_acc: 0.8556\n",
      "[WARNING] model_1_weights_20_epochs.h5 already exists - overwrite? [y/n]y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:18:11: Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TIP] Next time specify overwrite=True in save_weights!\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    nb_epoch=nb_epoch,\n",
    "    nb_val_samples=nb_validation_samples,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=2)\n",
    "model.save_weights(\"model_1_weights_{}_epochs.h5\".format(nb_epoch))\n",
    "logging.info(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Credits\n",
    "- <a href=\"https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\" target=\"_blank\">https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
